{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from keras.layers import Input, Dense, Reshape, Dropout, Bidirectional, LSTM\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes():\n",
    "    \"\"\" Get all the notes and chords from the midi files \"\"\"\n",
    "    notes = []\n",
    "\n",
    "    for file in glob.glob(\"midi_songs/*.mid\"):\n",
    "        midi = converter.parse(file)\n",
    "\n",
    "        print(\"Parsing %s\" % file)\n",
    "\n",
    "        notes_to_parse = None\n",
    "\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "            \n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    return notes\n",
    "\n",
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = 100\n",
    "\n",
    "    # Get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "    # Create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # Reshape the input into a format compatible with LSTM layers\n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    \n",
    "    # Normalize input between -1 and 1\n",
    "    network_input = (network_input - float(n_vocab)/2) / (float(n_vocab)/2)\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "\n",
    "    return (network_input, network_output)\n",
    "\n",
    "def generate_notes(model, network_input, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # pick a random sequence from the input as a starting point for the prediction\n",
    "    start = numpy.random.randint(0, len(network_input)-1)\n",
    "    \n",
    "    # Get pitch names and store in a dictionary\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "    print (int_to_note)\n",
    "\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "\n",
    "    # generate 500 notes\n",
    "    for note_index in range(500):\n",
    "        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "        index = numpy.argmax(prediction)\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "        \n",
    "        pattern = numpy.append(pattern,index)\n",
    "        #pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    return prediction_output\n",
    "  \n",
    "def create_midi(prediction_output, filename):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for item in prediction_output:\n",
    "        pattern = item[0]\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='{}.mid'.format(filename))\n",
    "\n",
    "class GAN():\n",
    "    def __init__(self, rows):\n",
    "        self.seq_length = rows\n",
    "        self.seq_shape = (self.seq_length, 1)\n",
    "        self.latent_dim = 1000\n",
    "        self.disc_loss = []\n",
    "        self.gen_loss =[]\n",
    "        \n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates note sequences\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        generated_seq = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        validity = self.discriminator(generated_seq)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(512, input_shape=self.seq_shape, return_sequences=True))\n",
    "        model.add(Bidirectional(LSTM(512)))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        seq = Input(shape=self.seq_shape)\n",
    "        validity = model(seq)\n",
    "\n",
    "        return Model(seq, validity)\n",
    "      \n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.seq_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.seq_shape))\n",
    "        model.summary()\n",
    "        \n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        seq = model(noise)\n",
    "\n",
    "        return Model(noise, seq)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load and convert the data\n",
    "        notes = get_notes()\n",
    "        n_vocab = len(set(notes))\n",
    "        X_train, y_train = prepare_sequences(notes, n_vocab)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        real = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        \n",
    "        # Training the model\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # Training the discriminator\n",
    "            # Select a random batch of note sequences\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            real_seqs = X_train[idx]\n",
    "\n",
    "            #noise = np.random.choice(range(484), (batch_size, self.latent_dim))\n",
    "            #noise = (noise-242)/242\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Generate a batch of new note sequences\n",
    "            gen_seqs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(real_seqs, real)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_seqs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "\n",
    "            #  Training the Generator\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Train the generator (to have the discriminator label samples as real)\n",
    "            g_loss = self.combined.train_on_batch(noise, real)\n",
    "\n",
    "            # Print the progress and save into loss lists\n",
    "            if epoch % sample_interval == 0:\n",
    "              print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "              self.disc_loss.append(d_loss[0])\n",
    "              self.gen_loss.append(g_loss)\n",
    "        #print (notes)\n",
    "        self.generate(notes)\n",
    "        self.plot_loss()\n",
    "        \n",
    "    def generate(self, input_notes):\n",
    "        # Get pitch names and store in a dictionary\n",
    "        notes = input_notes\n",
    "        pitchnames = sorted(set(item for item in notes))\n",
    "        int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "        #print (int_to_note)\n",
    "        # Use random noise to generate sequences\n",
    "        noise = np.random.normal(0, 1, (1, self.latent_dim))\n",
    "        predictions = self.generator.predict(noise)\n",
    "        #print (predictions)\n",
    "        pred_notes = [x*242+242 for x in predictions[0]]\n",
    "        #print (pred_notes)\n",
    "        notess = []\n",
    "        for x in pred_notes:\n",
    "            if int(x)>=len(int_to_note):\n",
    "                notess.append(len(int_to_note)-1)\n",
    "            else:\n",
    "                notess.append(x)\n",
    "        pred_notes = [int_to_note[int(x)] for x in notess]\n",
    "        \n",
    "        create_midi(pred_notes, 'gan_final')\n",
    "        \n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.disc_loss, c='red')\n",
    "        plt.plot(self.gen_loss, c='blue')\n",
    "        plt.title(\"GAN Loss per Epoch\")\n",
    "        plt.legend(['Discriminator', 'Generator'])\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.savefig('GAN_Loss_per_Epoch_final.png', transparent=True)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_27 (LSTM)               (None, 100, 512)          1052672   \n",
      "_________________________________________________________________\n",
      "bidirectional_14 (Bidirectio (None, 1024)              4198400   \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_66 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_67 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 5,907,457\n",
      "Trainable params: 5,907,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_95 (Dense)             (None, 256)               256256    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_68 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_69 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_70 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 100)               102500    \n",
      "_________________________________________________________________\n",
      "reshape_14 (Reshape)         (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 1,022,820\n",
      "Trainable params: 1,019,236\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n",
      "Parsing midi_songs/149_soul_105_fill_4-4.mid\n",
      "Parsing midi_songs/147_soul_105_fill_4-4.mid\n",
      "Parsing midi_songs/144_soul_105_fill_4-4.mid\n",
      "Parsing midi_songs/146_soul_105_fill_4-4.mid\n",
      "Parsing midi_songs/153_soul_98_fill_4-4.mid\n",
      "Parsing midi_songs/148_soul_105_fill_4-4.mid\n",
      "Parsing midi_songs/156_soul_98_fill_4-4.mid\n",
      "Parsing midi_songs/158_soul_98_fill_4-4.mid\n",
      "Parsing midi_songs/154_soul_98_fill_4-4.mid\n",
      "Parsing midi_songs/151_soul_98_beat_4-4.mid\n",
      "Parsing midi_songs/159_soul_98_beat_4-4.mid\n",
      "Parsing midi_songs/145_soul_105_fill_4-4.mid\n",
      "Parsing midi_songs/157_soul_98_fill_4-4.mid\n",
      "Parsing midi_songs/155_soul_98_fill_4-4.mid\n",
      "Parsing midi_songs/152_soul_98_fill_4-4.mid\n",
      "Parsing midi_songs/150_soul_105_beat_4-4.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bikash/anaconda3/lib/python3.6/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.693387, acc.: 50.00%] [G loss: 0.688721]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bikash/anaconda3/lib/python3.6/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [D loss: 0.677536, acc.: 77.50%] [G loss: 0.683964]\n",
      "2 [D loss: 0.640956, acc.: 82.50%] [G loss: 0.672194]\n",
      "3 [D loss: 0.553705, acc.: 82.50%] [G loss: 0.738159]\n",
      "4 [D loss: 0.485589, acc.: 87.50%] [G loss: 0.856678]\n"
     ]
    }
   ],
   "source": [
    "gan = GAN(rows=100)    \n",
    "gan.train(epochs=5, batch_size=20, sample_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate( input_notes):\n",
    "    # Get pitch names and store in a dictionary\n",
    "    notes = input_notes\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "        \n",
    "    # Use random noise to generate sequences\n",
    "    #noise = np.random.normal(0, 1, (1, self.latent_dim))\n",
    "    predictions = [[0.2424,0.224]]\n",
    "        \n",
    "    pred_notes = [x*242+242 for x in predictions[0]]\n",
    "    print (int(x))\n",
    "    pred_notes = [int_to_note[int(x)] for x in pred_notes]\n",
    "        \n",
    "    #create_midi(pred_notes, 'gan_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_notes = ['B2', 'D2', 'D2', 'E2', 'D2', 'D2', 'E2', 'D2', 'D3', 'C3', 'E2', 'D2', 'B2', 'D2', '11.0', 'D2', 'D2', '7.0', 'D2', '7.0', '7.0', '10.0.2', 'D2', '10.0', 'D2', 'D2', '0.4', 'D2', '0.4', 'C3', '11.0', 'D2', '0.1', 'C3', 'E2', 'C2', 'C3', 'C2', 'C2', 'E2', '2.8', 'D2', 'E2', 'B2', 'D2', 'B-3', 'C2', '2.7', '2.7', '2.7', '11.4', '2.8', 'D2', 'D2', 'D2', 'D2', 'D2', 'D2', 'D2', 'C#2', 'E2', 'C3', 'D2', 'C#2', 'C3', 'B2', 'D2', 'E2', '8.0', 'B2', 'D2', '4.8', 'C3', 'G2', 'B-3', 'D3', 'D2', 'D2', 'E2', 'D2', 'D2', 'E2', 'D3', 'C3', 'C#2', 'A2', 'D2', 'E2', 'C3', 'E2', 'C3', 'G2', 'G3', 'G#2', '11.0.4', '11.2', '0.2', 'C#2', 'C3', 'B2', '0.4', 'D2', 'B2', 'D2', '0.2', 'D2', '0.4', 'D3', '11.0', 'D2', '0.2', 'B2', 'C2', 'C3', 'C3', '11.0', 'D2', '0.2', '1.2', '7.0', 'G2', '7.0', 'F#2', '0.2', 'B-0', 'D2', '10.0', 'D2', 'B-0', '0.1', 'D2', 'B-0', '0.2', '0.6', 'F#2', 'C2', '10.0', '10.0', 'D2', 'B-0', 'C2', '10.0', 'D2', 'B-0', '0.2', '10.0', 'C3', 'D3', 'C3', 'C#2', 'E2', 'E2', 'G#2', 'C3', 'D3', 'D3', 'D2', 'E2', 'D2', 'A2', 'G2', '10.11', '11.2', '11.2', '11.0.2', '11.0.2', '11.0.2', '11.0.2', '11.0.2', '11.0.2', 'G#2', 'D2', 'E2', 'D2', 'E2', 'D2', '0.6', 'B-0', '0.4.8', '10.2', 'F#2', '10.0', 'D2', 'D1', '0.4.8', '10.2', 'F#2', '0.6', 'D2', 'B-0', '0.4.8', '2.6', 'F#2', '10.0', 'B-0', '8.0.2', 'B-0', 'D2', '0.6', 'B-0', '0.1', 'B-0', 'F#2', '0.6', 'F#2', 'B-0', '8.0', 'D2', 'B-0', 'F#2', 'C2', 'F#2', 'F#2', 'B-0', '10.0', '10.0', 'B-2', 'C2', 'D2', 'E2', 'C3', '8.11', 'D2', 'D2', 'C2', 'F#2', '7.0', 'D1', '2.8', 'C2', 'B-0', '0.6', 'F#2', 'B-0', '0.2', 'F#2', 'B-0', 'B-0', 'C2', 'B-0', '0.4', 'B-0', 'B-0', '10.0', 'E2', 'D2', '8.0.2', 'D2', 'D2', 'C2', '7.0', 'B-0', 'B-0', '0.4', 'D2', 'B-0', '10.0', '0.6', 'F#2', 'B-0', '0.2', 'B-0', 'F#2', '0.6', 'F#2', 'B-0', '0.4.8', 'D2', 'D1', '8.0', 'D2', 'C#2', 'E2', 'E2', '0.4.8', 'D2', 'D2', 'C2', '7.0', 'E-3', 'G3', 'G#2', 'F3', 'F3', 'G3', 'C#3', '5.8', 'C#3', 'E-3', 'G3', 'G#2', 'E-3', 'F3', 'G3', 'C#3', '3.8', 'C#3', 'E-3', 'C#3', '3.8', 'F3', 'E-3', 'E-3', '5.8', 'E-3', 'E-3', 'E-3', 'G#2', 'E-3', 'F3', 'E-3', 'E-3', '7.0', '0.3', '7.0', 'D2', '0.2.7', '0.2.7', '0.2.7', '10.0.2', '10.0.1', 'D2', 'D2', 'D2', 'D2', 'E2', 'G#2', 'D2', 'E2', 'E2', 'G#2', 'D3', 'D2', '7.0', 'B-0', '0.4', 'B-0', '0.6', 'F#2', 'B-0', '0.4', 'F#2', 'B-0', 'B-0', '0.6', 'B-0', 'B-0', '0.4', 'B-0', '10.0', '10.0', 'B-0', 'F#2', 'B-0', '0.4', 'B-0', 'F#2', '0.6', 'B-0', 'B-0', 'B-0', '0.4', 'D2', 'B-0', 'B-0', '0.6', '10.0', 'F#2', 'F#2', 'F#2', '0.4', 'F#2', 'B-0', '0.6', '10.0', 'B-0', 'B-0', 'F#2', '0.4', 'D1', 'C2', 'D1', 'D2', '0.4.8', 'D2', '0.4', 'D2', '0.4.8', 'D3', 'B2', 'C2', 'G3', '7.0', 'B-0', '0.4', 'B-0', 'B-0', '0.2', '10.0', 'B-0', 'F#2', 'B-0', '0.4', 'F#2', 'B-0', 'B-0', '10.0', 'B-0', 'B-0', 'B-0', '0.4', 'B-0', 'B-0', '10.0', '10.0', 'D1', '0.2', 'D2', '8.0', 'D2', 'C#2', '4.8', 'B-2', '7.8.0', 'B-0', 'B-0', '0.4', 'B-0', 'B-0', 'B-0', '10.0', 'B-0', 'B-0', 'F#2', '0.4', 'B-0', 'B-0', 'B-0', '10.0', 'B-0', 'B-0', 'B-0', '0.4', 'B-0', 'D1', 'D2', '4.8', 'D2', 'D2', '4.8', 'D2', '4.8', 'D3', 'B-3', 'C2', 'G3', '11.0', '2.8', 'D2', 'F3', 'F#2', '0.3', 'F#2', 'F3', '0.4.8', 'D2', 'F3', 'F#2', '0.3', 'F#2', 'F3', '0.4.8', 'D2', 'F3', 'F#2', '0.3', 'F#2', 'F3', 'E-3', '0.4.8', 'D2', 'E-3', 'F#2', '7.0', 'E-3', '0.4.8', 'D2', 'F3', 'F#2', '0.3', 'B-0', 'E-3', '1.3.7', '0.4.8', 'D2', 'F3', '0.6', '0.3', 'F#2', 'E-3', '0.4.8', 'D2', 'F3', '10.0', '7.0', 'E-3', '7.0', '11.0', 'E-3', '10.0', '8.10.0.1.2.3', 'E-3', '4.8', 'D2', 'F3', 'F#2', '0.3', 'F#2', 'F3', '8.0.2', 'D2', 'F3', 'F#2', '0.3', 'F#2', 'E-3', '0.4.8', 'D2', 'F3', 'F#2', 'C2', '3.8', 'B-2', '0.5', 'E-3', '4.8', 'D2', 'B2', 'F#2', '7.0', 'F#2', 'F3', '0.4.8', 'D2', 'F3', 'F#2', '0.3', 'F#2', 'E-3', '4.8', 'A2', 'A2', 'A2', '11.0', '7.0', '4.5.8.0', '7.0', 'D2', '0.2.3', '11.0', 'D2', '0.3', '0.3', 'B3', 'D2', '0.2.7', 'D1', 'C2', 'B-2', '7.0', 'C2', '7.0', '0.2', '11.0', '11.0', '11.0', '7.0', '0.2', '11.0', '7.0', '0.2', '11.0', '7.10.0', '10.0.3', '11.0.2', '11.0.2', '11.0.2', '10.11.0', '11.0.2', '8.11.0.2', 'D2', 'D2', 'D2', 'D2', 'E2', 'E2', '2.8', 'D2', 'E2', 'C3', 'B2', 'D2', 'E2', 'C3', 'G2', 'G2', '8.11.0', 'E-3', '0.4.8', 'F3', 'F#2', '0.3', 'B-0', 'F3', '4.8', 'C2', 'D2', 'F3', 'F#2', '0.3', 'B-0', 'F3', 'C2', '0.4.8', 'D2', 'F3', 'F#2', '0.3', 'B-0', 'E-3', '0.3', '0.4.8', 'D2', 'C2', 'E-3', 'F#2', '7.0', 'B-0', 'B-0', '0.2', 'D2', 'D1', 'B-0', 'C2', 'F#2', 'B-0', 'B-0', '0.4', 'D2', 'B-0', 'B-0', 'G#2', 'E2', 'D2', 'E2', 'D2', '7.0', '2.3.7', '4.8', 'B-0', 'D2', '10.0', 'D2', 'B-0', '0.4', 'B-0', 'C2', 'B-0', '0.4', 'D2', 'B-0', 'D2', '0.6', 'B-0', '0.4', '10.2', '8.0', 'D2', 'B-0', '0.4', 'D2', 'B-0', 'D2', '0.6', 'D2', 'B-0', 'C2', '0.4', 'D2', 'B-0', 'D2', '0.6', 'D2', 'B-0', '0.4', 'D2', 'B-0', 'C2', 'D2', '0.6', '0.2', 'D2', 'C2', 'D2', 'E2', 'E2', 'D2', '7.0', 'D2', 'D1', '0.4.8', 'D2', 'B-0', '0.2', '0.6', 'D2', 'B-0', '0.4.8', 'D2', 'B-0', 'D2', '0.6', 'D2', 'B-0', '0.4.8', 'B-0', '0.2', '0.6', 'D2', '0.2', '8.0', 'C#2', 'E2', '7.0', 'B-0', '0.4.8', 'B-0', '0.6', 'F#2', 'D1', '0.4.8', 'B-0', 'B-0', '0.6', '0.2', 'B-2', '0.4.8', '0.4', 'D1', 'G#2', '0.2', 'D2', 'E2', 'C2', 'B2', '0.2', 'E2', 'D2', '7.0', 'B-0', '0.4.8', 'B-0', 'B-0', '0.6', 'F#2', 'B-0', '0.4', 'B-0', 'F#2', '0.6', 'B-0', '0.4', 'B-0', 'B-0', 'B-0', '0.6', 'F#2', 'D1', 'B-2', '8.0', 'D2', 'E2', 'E2', 'D2', '8.11.0', 'F#2', 'G3', '0.4', 'F#2', 'B-0', 'B-0', '0.6', 'B-0', 'B-0', 'F#2', '0.4', 'B-0', 'B-0', '10.0', 'G2', '2.7', '2.7', '2.4', 'D2', 'C3', 'C3', 'C3', 'D3', 'E2', 'D2', 'C2', 'D3', 'C3', 'C2', 'C#2', 'D2', 'C2', 'B2', 'D2', 'D2', 'E2', 'D2', 'C2', 'C2', 'B2', 'E2', 'D2', 'D2', 'E2', 'B-0', 'B2', '2.3', '11.2', '11.2', '11.0.2', '11.0.2', '11.0.2', '11.0.2', '11.0.2', 'D2', 'D2', 'D2', 'D2', 'D3', 'E2', 'D2', 'E2', 'D3', 'B2', 'B2', 'G2', 'G2', 'B-3', 'G2', 'G#2', 'G#2', 'G#2', 'D2', 'G#2', 'E2', 'D2', 'C#2', 'E2', 'G#2', 'E2', 'D2', '7.0', 'D2', 'D1', '0.4.8', '10.2', 'F#2', '10.0', 'D2', 'D1', '0.4.8', '10.2', 'F#2', '10.0', 'D2', 'B-0', '0.4', '10.2', 'F#2', 'C2', 'D2', 'D1', '4.8', 'C2', '10.2', 'B-0', '10.0', 'D2', 'B-0', '0.4', '10.2', 'F#2', 'C2', 'D2', 'B-0', '10.0.4', 'D2', 'B-0', 'D2', '10.0', 'D2', '0.2', 'D2', '8.0.2', 'E2', '0.2', 'C3', '0.4', 'D2', '11.0', 'C3', '0.4', 'D2', '7.0', 'G2', '11.0', 'B-2', '0.4.8', '10.2', 'F#2', '0.6', 'D2', 'D1', '0.4.8', '10.2', 'F#2', 'C2', 'D2', 'D1', '4.8', 'C2', '10.2', 'F#2', '0.6', 'D2', 'D1', '8.0', 'E2', '10.2', 'F#2', '10.0', 'D2', 'D1', '0.4.8', '10.1', 'G#2', '0.6', 'D2', 'D1', '0.4.8', '0.2', '10.0', 'E2', '0.4', 'C2', 'D2', '0.4', 'D2', '8.0.2', 'D2', '0.4', 'C3', '11.0', 'D2', 'C#2', '7.0', '11.0', 'D2', 'B-0', '0.4.8', '2', 'G#2', '0.6', 'D2', 'D1', '0.4.8', '2', '0.6', 'D2', 'D1', '4.8', 'C2', '2', 'F#2', 'C2', 'F#2', 'D2', 'D1', '4.8', 'C2', '10.2', 'B-0', '10.0', 'D2', 'D1', '0.4.8', '10.2', 'B-0', '10.0', 'D2', 'D1', '0.4.8', '10.2', 'F#2', '10.0', 'D2', 'D1', '0.2.4', '0.2.4', 'D2', '8.0.2', 'D2', 'C2', 'D2', 'D2', 'D2', 'D2', 'D2', 'D2', 'D2', '7.0', 'B-2', '4.6.8.0', 'D2', 'B-0', 'D2', '0.6', 'D2', 'D1', '0.4.8', 'B-0', 'D2', '0.6', 'D2', 'D1', '0.4.8', 'F#2', '10.2', 'F#2', '10.0', 'D2', 'D1', '0.4.8', 'F#2', 'C2', '10.2', 'F#2', '10.0', 'D2', 'D1', '8.10.0.4', 'C2', '10.2', 'D2', '10.0', 'D2', 'D2', '0.2', 'D2', '4.8.10', 'C2', '0.2', 'D1', 'D2', 'D2', '8.10.0', 'D2', '0.2', '0.2.4', '0.1.2', 'D2', '0.2', 'D2', '0.2', 'C3', '7.0', 'G2', '7.0', 'D2', 'D2', '8.11.0', 'D2', 'D1', '0.4.8', '2', 'B-0', '0.6', 'D2', '2', '0.4.8', 'F#2', 'D2', 'D1', 'D2', '10.0', 'D2', '0.2', 'D1', '4.6.8.0', 'D2', 'D1', 'D2', '6.8.0', 'D2', 'B-0', '8.10.0.4', 'D2', 'B-0', '10.0', 'D2', 'D1', '8.10.0.4', '0.2', 'B-0', '2.6', '0.6', 'D2', 'D1', '8.10.0.4', 'D2', 'D1', 'D2', '0.2', '0.2', 'D2', 'C3', 'D2', 'E2', 'D2', 'C3', 'D2', 'E2', 'E2', 'E2', 'D2', 'G2', 'G#2', 'C3', '11.0', 'B-2', '8.10.0.4', 'D2', 'B-0', 'D2', '0.6', 'D2', 'D2', 'D1', '0.4.8', 'B-0', 'D2', 'B-0', 'D2', 'D2', '0.6', 'D2', 'D1', 'B-2', 'G#2', '10.0.4', 'D2', 'B-0', 'D2', '0.6', 'D2', 'B-0', '10.0.4', 'D2', '0.2', 'D2', '8.0.2', 'D2', 'D2', '0.4', 'D2', 'D2', '0.4', 'E2', '0.2', 'D2', '0.4', 'C3', '11.0', 'D2', '0.4', 'G#2', 'C3', 'G2', 'C2', 'G3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['B2', 'D2', 'D2', 'E2', 'D2', 'D2', 'E2', 'D2', 'D3', 'C3', 'E2', 'D2', 'B2', 'D2', '11.0', 'D2', 'D2', '7.0', 'D2', '7.0', '7.0', '10.0.2', 'D2', '10.0', 'D2', 'D2', '0.4', 'D2', '0.4', 'C3', '11.0', 'D2', '0.1', 'C3', 'E2', 'C2', 'C3', 'C2', 'C2', 'E2', '2.8', 'D2', 'E2', 'B2', 'D2', 'B-3', 'C2', '2.7', '2.7', '2.7', '11.4', '2.8', 'D2', 'D2', 'D2', 'D2', 'D2', 'D2', 'D2', 'C#2', 'E2', 'C3', 'D2', 'C#2', 'C3', 'B2', 'D2', 'E2', '8.0', 'B2', 'D2', '4.8', 'C3', 'G2', 'B-3', 'D3', 'D2', 'D2', 'E2', 'D2', 'D2', 'E2', 'D3', 'C3', 'C#2', 'A2', 'D2', 'E2', 'C3', 'E2', 'C3', 'G2', 'G3', 'G#2', '11.0.4', '11.2', '0.2', 'C#2', 'C3', 'B2', '0.4', 'D2', 'B2', 'D2', '0.2', 'D2', '0.4', 'D3', '11.0', 'D2', '0.2', 'B2', 'C2', 'C3', 'C3', '11.0', 'D2', '0.2', '1.2', '7.0', 'G2', '7.0', 'F#2', '0.2', 'B-0', 'D2', '10.0', 'D2', 'B-0', '0.1', 'D2', 'B-0', '0.2', '0.6', 'F#2', 'C2', '10.0', '10.0', 'D2', 'B-0', 'C2', '10.0', 'D2', 'B-0', '0.2', '10.0', 'C3', 'D3', 'C3', 'C#2', 'E2', 'E2', 'G#2', 'C3', 'D3', 'D3', 'D2', 'E2', 'D2', 'A2', 'G2', '10.11', '11.2', '11.2', '11.0.2', '11.0.2', '11.0.2', '11.0.2', '11.0.2', '11.0.2', 'G#2', 'D2', 'E2', 'D2', 'E2', 'D2', '0.6', 'B-0', '0.4.8', '10.2', 'F#2', '10.0', 'D2', 'D1', '0.4.8', '10.2', 'F#2', '0.6', 'D2', 'B-0', '0.4.8', '2.6', 'F#2', '10.0', 'B-0', '8.0.2', 'B-0', 'D2', '0.6', 'B-0', '0.1', 'B-0', 'F#2', '0.6', 'F#2', 'B-0', '8.0', 'D2', 'B-0', 'F#2', 'C2', 'F#2', 'F#2', 'B-0', '10.0', '10.0', 'B-2', 'C2', 'D2', 'E2', 'C3', '8.11', 'D2', 'D2', 'C2', 'F#2', '7.0', 'D1', '2.8', 'C2', 'B-0', '0.6', 'F#2', 'B-0', '0.2', 'F#2', 'B-0', 'B-0', 'C2', 'B-0', '0.4', 'B-0', 'B-0', '10.0', 'E2', 'D2', '8.0.2', 'D2', 'D2', 'C2', '7.0', 'B-0', 'B-0', '0.4', 'D2', 'B-0', '10.0', '0.6', 'F#2', 'B-0', '0.2', 'B-0', 'F#2', '0.6', 'F#2', 'B-0', '0.4.8', 'D2', 'D1', '8.0', 'D2', 'C#2', 'E2', 'E2', '0.4.8', 'D2', 'D2', 'C2', '7.0', 'E-3', 'G3', 'G#2', 'F3', 'F3', 'G3', 'C#3', '5.8', 'C#3', 'E-3', 'G3', 'G#2', 'E-3', 'F3', 'G3', 'C#3', '3.8', 'C#3', 'E-3', 'C#3', '3.8', 'F3', 'E-3', 'E-3', '5.8', 'E-3', 'E-3', 'E-3', 'G#2', 'E-3', 'F3', 'E-3', 'E-3', '7.0', '0.3', '7.0', 'D2', '0.2.7', '0.2.7', '0.2.7', '10.0.2', '10.0.1', 'D2', 'D2', 'D2', 'D2', 'E2', 'G#2', 'D2', 'E2', 'E2', 'G#2', 'D3', 'D2', '7.0', 'B-0', '0.4', 'B-0', '0.6', 'F#2', 'B-0', '0.4', 'F#2', 'B-0', 'B-0', '0.6', 'B-0', 'B-0', '0.4', 'B-0', '10.0', '10.0', 'B-0', 'F#2', 'B-0', '0.4', 'B-0', 'F#2', '0.6', 'B-0', 'B-0', 'B-0', '0.4', 'D2', 'B-0', 'B-0', '0.6', '10.0', 'F#2', 'F#2', 'F#2', '0.4', 'F#2', 'B-0', '0.6', '10.0', 'B-0', 'B-0', 'F#2', '0.4', 'D1', 'C2', 'D1', 'D2', '0.4.8', 'D2', '0.4', 'D2', '0.4.8', 'D3', 'B2', 'C2', 'G3', '7.0', 'B-0', '0.4', 'B-0', 'B-0', '0.2', '10.0', 'B-0', 'F#2', 'B-0', '0.4', 'F#2', 'B-0', 'B-0', '10.0', 'B-0', 'B-0', 'B-0', '0.4', 'B-0', 'B-0', '10.0', '10.0', 'D1', '0.2', 'D2', '8.0', 'D2', 'C#2', '4.8', 'B-2', '7.8.0', 'B-0', 'B-0', '0.4', 'B-0', 'B-0', 'B-0', '10.0', 'B-0', 'B-0', 'F#2', '0.4', 'B-0', 'B-0', 'B-0', '10.0', 'B-0', 'B-0', 'B-0', '0.4', 'B-0', 'D1', 'D2', '4.8', 'D2', 'D2', '4.8', 'D2', '4.8', 'D3', 'B-3', 'C2', 'G3', '11.0', '2.8', 'D2', 'F3', 'F#2', '0.3', 'F#2', 'F3', '0.4.8', 'D2', 'F3', 'F#2', '0.3', 'F#2', 'F3', '0.4.8', 'D2', 'F3', 'F#2', '0.3', 'F#2', 'F3', 'E-3', '0.4.8', 'D2', 'E-3', 'F#2', '7.0', 'E-3', '0.4.8', 'D2', 'F3', 'F#2', '0.3', 'B-0', 'E-3', '1.3.7', '0.4.8', 'D2', 'F3', '0.6', '0.3', 'F#2', 'E-3', '0.4.8', 'D2', 'F3', '10.0', '7.0', 'E-3', '7.0', '11.0', 'E-3', '10.0', '8.10.0.1.2.3', 'E-3', '4.8', 'D2', 'F3', 'F#2', '0.3', 'F#2', 'F3', '8.0.2', 'D2', 'F3', 'F#2', '0.3', 'F#2', 'E-3', '0.4.8', 'D2', 'F3', 'F#2', 'C2', '3.8', 'B-2', '0.5', 'E-3', '4.8', 'D2', 'B2', 'F#2', '7.0', 'F#2', 'F3', '0.4.8', 'D2', 'F3', 'F#2', '0.3', 'F#2', 'E-3', '4.8', 'A2', 'A2', 'A2', '11.0', '7.0', '4.5.8.0', '7.0', 'D2', '0.2.3', '11.0', 'D2', '0.3', '0.3', 'B3', 'D2', '0.2.7', 'D1', 'C2', 'B-2', '7.0', 'C2', '7.0', '0.2', '11.0', '11.0', '11.0', '7.0', '0.2', '11.0', '7.0', '0.2', '11.0', '7.10.0', '10.0.3', '11.0.2', '11.0.2', '11.0.2', '10.11.0', '11.0.2', '8.11.0.2', 'D2', 'D2', 'D2', 'D2', 'E2', 'E2', '2.8', 'D2', 'E2', 'C3', 'B2', 'D2', 'E2', 'C3', 'G2', 'G2', '8.11.0', 'E-3', '0.4.8', 'F3', 'F#2', '0.3', 'B-0', 'F3', '4.8', 'C2', 'D2', 'F3', 'F#2', '0.3', 'B-0', 'F3', 'C2', '0.4.8', 'D2', 'F3', 'F#2', '0.3', 'B-0', 'E-3', '0.3', '0.4.8', 'D2', 'C2', 'E-3', 'F#2', '7.0', 'B-0', 'B-0', '0.2', 'D2', 'D1', 'B-0', 'C2', 'F#2', 'B-0', 'B-0', '0.4', 'D2', 'B-0', 'B-0', 'G#2', 'E2', 'D2', 'E2', 'D2', '7.0', '2.3.7', '4.8', 'B-0', 'D2', '10.0', 'D2', 'B-0', '0.4', 'B-0', 'C2', 'B-0', '0.4', 'D2', 'B-0', 'D2', '0.6', 'B-0', '0.4', '10.2', '8.0', 'D2', 'B-0', '0.4', 'D2', 'B-0', 'D2', '0.6', 'D2', 'B-0', 'C2', '0.4', 'D2', 'B-0', 'D2', '0.6', 'D2', 'B-0', '0.4', 'D2', 'B-0', 'C2', 'D2', '0.6', '0.2', 'D2', 'C2', 'D2', 'E2', 'E2', 'D2', '7.0', 'D2', 'D1', '0.4.8', 'D2', 'B-0', '0.2', '0.6', 'D2', 'B-0', '0.4.8', 'D2', 'B-0', 'D2', '0.6', 'D2', 'B-0', '0.4.8', 'B-0', '0.2', '0.6', 'D2', '0.2', '8.0', 'C#2', 'E2', '7.0', 'B-0', '0.4.8', 'B-0', '0.6', 'F#2', 'D1', '0.4.8', 'B-0', 'B-0', '0.6', '0.2', 'B-2', '0.4.8', '0.4', 'D1', 'G#2', '0.2', 'D2', 'E2', 'C2', 'B2', '0.2', 'E2', 'D2', '7.0', 'B-0', '0.4.8', 'B-0', 'B-0', '0.6', 'F#2', 'B-0', '0.4', 'B-0', 'F#2', '0.6', 'B-0', '0.4', 'B-0', 'B-0', 'B-0', '0.6', 'F#2', 'D1', 'B-2', '8.0', 'D2', 'E2', 'E2', 'D2', '8.11.0', 'F#2', 'G3', '0.4', 'F#2', 'B-0', 'B-0', '0.6', 'B-0', 'B-0', 'F#2', '0.4', 'B-0', 'B-0', '10.0', 'G2', '2.7', '2.7', '2.4', 'D2', 'C3', 'C3', 'C3', 'D3', 'E2', 'D2', 'C2', 'D3', 'C3', 'C2', 'C#2', 'D2', 'C2', 'B2', 'D2', 'D2', 'E2', 'D2', 'C2', 'C2', 'B2', 'E2', 'D2', 'D2', 'E2', 'B-0', 'B2', '2.3', '11.2', '11.2', '11.0.2', '11.0.2', '11.0.2', '11.0.2', '11.0.2', 'D2', 'D2', 'D2', 'D2', 'D3', 'E2', 'D2', 'E2', 'D3', 'B2', 'B2', 'G2', 'G2', 'B-3', 'G2', 'G#2', 'G#2', 'G#2', 'D2', 'G#2', 'E2', 'D2', 'C#2', 'E2', 'G#2', 'E2', 'D2', '7.0', 'D2', 'D1', '0.4.8', '10.2', 'F#2', '10.0', 'D2', 'D1', '0.4.8', '10.2', 'F#2', '10.0', 'D2', 'B-0', '0.4', '10.2', 'F#2', 'C2', 'D2', 'D1', '4.8', 'C2', '10.2', 'B-0', '10.0', 'D2', 'B-0', '0.4', '10.2', 'F#2', 'C2', 'D2', 'B-0', '10.0.4', 'D2', 'B-0', 'D2', '10.0', 'D2', '0.2', 'D2', '8.0.2', 'E2', '0.2', 'C3', '0.4', 'D2', '11.0', 'C3', '0.4', 'D2', '7.0', 'G2', '11.0', 'B-2', '0.4.8', '10.2', 'F#2', '0.6', 'D2', 'D1', '0.4.8', '10.2', 'F#2', 'C2', 'D2', 'D1', '4.8', 'C2', '10.2', 'F#2', '0.6', 'D2', 'D1', '8.0', 'E2', '10.2', 'F#2', '10.0', 'D2', 'D1', '0.4.8', '10.1', 'G#2', '0.6', 'D2', 'D1', '0.4.8', '0.2', '10.0', 'E2', '0.4', 'C2', 'D2', '0.4', 'D2', '8.0.2', 'D2', '0.4', 'C3', '11.0', 'D2', 'C#2', '7.0', '11.0', 'D2', 'B-0', '0.4.8', '2', 'G#2', '0.6', 'D2', 'D1', '0.4.8', '2', '0.6', 'D2', 'D1', '4.8', 'C2', '2', 'F#2', 'C2', 'F#2', 'D2', 'D1', '4.8', 'C2', '10.2', 'B-0', '10.0', 'D2', 'D1', '0.4.8', '10.2', 'B-0', '10.0', 'D2', 'D1', '0.4.8', '10.2', 'F#2', '10.0', 'D2', 'D1', '0.2.4', '0.2.4', 'D2', '8.0.2', 'D2', 'C2', 'D2', 'D2', 'D2', 'D2', 'D2', 'D2', 'D2', '7.0', 'B-2', '4.6.8.0', 'D2', 'B-0', 'D2', '0.6', 'D2', 'D1', '0.4.8', 'B-0', 'D2', '0.6', 'D2', 'D1', '0.4.8', 'F#2', '10.2', 'F#2', '10.0', 'D2', 'D1', '0.4.8', 'F#2', 'C2', '10.2', 'F#2', '10.0', 'D2', 'D1', '8.10.0.4', 'C2', '10.2', 'D2', '10.0', 'D2', 'D2', '0.2', 'D2', '4.8.10', 'C2', '0.2', 'D1', 'D2', 'D2', '8.10.0', 'D2', '0.2', '0.2.4', '0.1.2', 'D2', '0.2', 'D2', '0.2', 'C3', '7.0', 'G2', '7.0', 'D2', 'D2', '8.11.0', 'D2', 'D1', '0.4.8', '2', 'B-0', '0.6', 'D2', '2', '0.4.8', 'F#2', 'D2', 'D1', 'D2', '10.0', 'D2', '0.2', 'D1', '4.6.8.0', 'D2', 'D1', 'D2', '6.8.0', 'D2', 'B-0', '8.10.0.4', 'D2', 'B-0', '10.0', 'D2', 'D1', '8.10.0.4', '0.2', 'B-0', '2.6', '0.6', 'D2', 'D1', '8.10.0.4', 'D2', 'D1', 'D2', '0.2', '0.2', 'D2', 'C3', 'D2', 'E2', 'D2', 'C3', 'D2', 'E2', 'E2', 'E2', 'D2', 'G2', 'G#2', 'C3', '11.0', 'B-2', '8.10.0.4', 'D2', 'B-0', 'D2', '0.6', 'D2', 'D2', 'D1', '0.4.8', 'B-0', 'D2', 'B-0', 'D2', 'D2', '0.6', 'D2', 'D1', 'B-2', 'G#2', '10.0.4', 'D2', 'B-0', 'D2', '0.6', 'D2', 'B-0', '10.0.4', 'D2', '0.2', 'D2', '8.0.2', 'D2', 'D2', '0.4', 'D2', 'D2', '0.4', 'E2', '0.2', 'D2', '0.4', 'C3', '11.0', 'D2', '0.4', 'G#2', 'C3', 'G2', 'C2', 'G3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F3'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300.6608, 296.20799999999997]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "300",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-41c8f9b6d84a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_notes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-ac3c6620a3b2>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(input_notes)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mpred_notes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m242\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m242\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred_notes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpred_notes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint_to_note\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_notes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#create_midi(pred_notes, 'gan_final')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-ac3c6620a3b2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mpred_notes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m242\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m242\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred_notes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpred_notes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint_to_note\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_notes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#create_midi(pred_notes, 'gan_final')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 300"
     ]
    }
   ],
   "source": [
    "generate(input_notes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
